{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "orAAOB5iopBwGOuTItXgbhbM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6555,
     "status": "ok",
     "timestamp": 1721609846694,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 420
    },
    "id": "orAAOB5iopBwGOuTItXgbhbM",
    "outputId": "896f0bdd-4d30-4f63-fef1-4b77c675ee40",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'LLaVA-Med-Retina'...\n",
      "remote: Enumerating objects: 343, done.\u001b[K\n",
      "remote: Total 343 (delta 0), reused 0 (delta 0), pack-reused 343 (from 1)\u001b[K\n",
      "Receiving objects: 100% (343/343), 77.08 MiB | 22.75 MiB/s, done.\n",
      "Resolving deltas: 100% (93/93), done.\n",
      "Updating files: 100% (210/210), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/D3F4LT4ST/LLaVA-Med-Retina.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "220a5591-b3a0-40bb-9568-63a7a063d10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/LLaVA-Med/Model/LLaVA-Med-Retina\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd \"/workspace/LLaVA-Med/Model/LLaVA-Med-Retina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82f76aeb-8f9b-4ce6-a6c6-0394d0e7d7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/LLaVA-Med\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "j--BYddm3zRv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 396,
     "status": "ok",
     "timestamp": 1721610951664,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 420
    },
    "id": "j--BYddm3zRv",
    "outputId": "8313cfff-b3fd-4e45-9569-c99827d65332"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llava-Med-Fine_Tuning.ipynb  Model  converted_data.json\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "Ef-WMPNQ_Ybo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 190177,
     "status": "ok",
     "timestamp": 1721611143517,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 420
    },
    "id": "Ef-WMPNQ_Ybo",
    "outputId": "bbe6cfcc-e77a-4acf-88f8-4c66993cf6ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.4.0\n",
      "Uninstalling torch-2.4.0:\n",
      "  Successfully uninstalled torch-2.4.0\n",
      "Found existing installation: torchvision 0.15.1+cu117\n",
      "Uninstalling torchvision-0.15.1+cu117:\n",
      "  Successfully uninstalled torchvision-0.15.1+cu117\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://download.pytorch.org/whl/cu117\n",
      "Collecting torch==2.0.0+cu117\n",
      "  Using cached https://download.pytorch.org/whl/cu117/torch-2.0.0%2Bcu117-cp310-cp310-linux_x86_64.whl (1843.9 MB)\n",
      "Collecting torchvision==0.15.1+cu117\n",
      "  Using cached https://download.pytorch.org/whl/cu117/torchvision-0.15.1%2Bcu117-cp310-cp310-linux_x86_64.whl (6.1 MB)\n",
      "Requirement already satisfied: torchaudio==2.0.1 in /usr/local/lib/python3.10/dist-packages (2.0.1+cu117)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0+cu117) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0+cu117) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0+cu117) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0+cu117) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0+cu117) (3.1.2)\n",
      "Collecting triton==2.0.0 (from torch==2.0.0+cu117)\n",
      "  Using cached https://download.pytorch.org/whl/triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1+cu117) (1.24.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1+cu117) (2.32.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1+cu117) (10.4.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0+cu117) (3.25.0)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0+cu117) (15.0.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0+cu117) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1+cu117) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1+cu117) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1+cu117) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1+cu117) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0+cu117) (1.3.0)\n",
      "Installing collected packages: triton, torch, torchvision\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.0.0\n",
      "    Uninstalling triton-3.0.0:\n",
      "      Successfully uninstalled triton-3.0.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llava 0.1.0 requires tokenizers==0.12.1, but you have tokenizers 0.19.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-2.0.0+cu117 torchvision-0.15.1+cu117 triton-2.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: openai==0.27.8 in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8) (4.66.5)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8) (3.10.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.8) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.8) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.8) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.27.8) (2022.12.7)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.27.8) (4.0.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: transformers 4.40.0\n",
      "Uninstalling transformers-4.40.0:\n",
      "  Successfully uninstalled transformers-4.40.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting git+https://github.com/huggingface/transformers@cae78c46\n",
      "  Cloning https://github.com/huggingface/transformers (to revision cae78c46) to /tmp/pip-req-build-5aka73hg\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-5aka73hg\n",
      "\u001b[33m  WARNING: Did not find branch or tag 'cae78c46', assuming revision or ref.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running command git checkout -q cae78c46\n",
      "  Resolved https://github.com/huggingface/transformers to commit cae78c46\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0.dev0) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0.dev0) (0.24.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0.dev0) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0.dev0) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0.dev0) (2024.7.24)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0.dev0) (2.32.3)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.28.0.dev0)\n",
      "  Using cached tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0.dev0) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0.dev0) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0.dev0) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0.dev0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0.dev0) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0.dev0) (2022.12.7)\n",
      "Using cached tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.28.0.dev0-py3-none-any.whl size=6827701 sha256=98e188f836dd703f79f4e172f9e228e03df9b3d4bd68f396eac2da6746acc1e3\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-jf0fwhe5/wheels/4a/a6/e7/edd247407688cf2bd34bc7db6e74b7a0a468d660f8d1342ad0\n",
      "Successfully built transformers\n",
      "Installing collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.19.1\n",
      "    Uninstalling tokenizers-0.19.1:\n",
      "      Successfully uninstalled tokenizers-0.19.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llava 0.1.0 requires tokenizers==0.12.1, but you have tokenizers 0.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed tokenizers-0.13.3 transformers-4.28.0.dev0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mObtaining file:///workspace/LLaVA-Med/Model/LLaVA-Med-Retina\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transformers@ git+https://github.com/huggingface/transformers.git@cae78c46 (from llava==0.1.0)\n",
      "  Cloning https://github.com/huggingface/transformers.git (to revision cae78c46) to /tmp/pip-install-rti0inm2/transformers_cf46d30153094471baafdbe3db050766\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-install-rti0inm2/transformers_cf46d30153094471baafdbe3db050766\n",
      "\u001b[33m  WARNING: Did not find branch or tag 'cae78c46', assuming revision or ref.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running command git checkout -q cae78c46\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit cae78c46\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from llava==0.1.0) (0.33.0)\n",
      "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from llava==0.1.0) (0.103.2)\n",
      "Requirement already satisfied: gradio==3.23 in /usr/local/lib/python3.10/dist-packages (from llava==0.1.0) (3.23.0)\n",
      "Requirement already satisfied: markdown2[all] in /usr/local/lib/python3.10/dist-packages (from llava==0.1.0) (2.5.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llava==0.1.0) (1.24.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from llava==0.1.0) (2.32.3)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from llava==0.1.0) (0.1.99)\n",
      "Collecting tokenizers==0.12.1 (from llava==0.1.0)\n",
      "  Using cached tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from llava==0.1.0) (2.0.0+cu117)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from llava==0.1.0) (0.15.1+cu117)\n",
      "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (from llava==0.1.0) (0.30.6)\n",
      "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from llava==0.1.0) (0.17.5)\n",
      "Requirement already satisfied: aiofiles in /usr/local/lib/python3.10/dist-packages (from gradio==3.23->llava==0.1.0) (23.2.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from gradio==3.23->llava==0.1.0) (3.10.5)\n",
      "Requirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.23->llava==0.1.0) (5.3.0)\n",
      "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio==3.23->llava==0.1.0) (0.4.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio==3.23->llava==0.1.0) (2024.6.1)\n",
      "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio==3.23->llava==0.1.0) (0.24.0)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from gradio==3.23->llava==0.1.0) (0.24.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from gradio==3.23->llava==0.1.0) (3.1.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.23->llava==0.1.0) (2.2.0)\n",
      "Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from gradio==3.23->llava==0.1.0) (2.1.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gradio==3.23->llava==0.1.0) (3.9.2)\n",
      "Requirement already satisfied: mdit-py-plugins<=0.3.3 in /usr/local/lib/python3.10/dist-packages (from gradio==3.23->llava==0.1.0) (0.3.3)\n",
      "Requirement already satisfied: orjson in /usr/local/lib/python3.10/dist-packages (from gradio==3.23->llava==0.1.0) (3.10.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from gradio==3.23->llava==0.1.0) (2.2.2)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from gradio==3.23->llava==0.1.0) (10.4.0)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from gradio==3.23->llava==0.1.0) (1.10.7)\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio==3.23->llava==0.1.0) (0.25.1)\n",
      "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio==3.23->llava==0.1.0) (0.0.9)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from gradio==3.23->llava==0.1.0) (6.0.1)\n",
      "Requirement already satisfied: semantic-version in /usr/local/lib/python3.10/dist-packages (from gradio==3.23->llava==0.1.0) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from gradio==3.23->llava==0.1.0) (4.12.2)\n",
      "Requirement already satisfied: websockets>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.23->llava==0.1.0) (11.0.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->llava==0.1.0) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->llava==0.1.0) (5.9.6)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate->llava==0.1.0) (0.4.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->llava==0.1.0) (3.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->llava==0.1.0) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->llava==0.1.0) (3.0)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->llava==0.1.0) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->llava==0.1.0) (3.25.0)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->llava==0.1.0) (15.0.7)\n",
      "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->llava==0.1.0) (3.7.1)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->llava==0.1.0) (0.27.0)\n",
      "Requirement already satisfied: pygments>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from markdown2[all]->llava==0.1.0) (2.16.1)\n",
      "Requirement already satisfied: wavedrom in /usr/local/lib/python3.10/dist-packages (from markdown2[all]->llava==0.1.0) (2.0.3.post3)\n",
      "Requirement already satisfied: latex2mathml in /usr/local/lib/python3.10/dist-packages (from markdown2[all]->llava==0.1.0) (3.77.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->llava==0.1.0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->llava==0.1.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->llava==0.1.0) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->llava==0.1.0) (2022.12.7)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers@ git+https://github.com/huggingface/transformers.git@cae78c46->llava==0.1.0) (2024.7.24)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers@ git+https://github.com/huggingface/transformers.git@cae78c46->llava==0.1.0) (4.66.5)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->llava==0.1.0) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn->llava==0.1.0) (0.14.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb->llava==0.1.0) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->llava==0.1.0) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->llava==0.1.0) (3.11.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->llava==0.1.0) (5.27.3)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->llava==0.1.0) (2.13.0)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb->llava==0.1.0) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->llava==0.1.0) (68.2.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio==3.23->llava==0.1.0) (4.19.2)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio==3.23->llava==0.1.0) (0.12.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->llava==0.1.0) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->llava==0.1.0) (1.1.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb->llava==0.1.0) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->llava==0.1.0) (4.0.11)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.0.0->markdown-it-py[linkify]>=2.0.0->gradio==3.23->llava==0.1.0) (0.1.2)\n",
      "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.23->llava==0.1.0) (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio==3.23->llava==0.1.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio==3.23->llava==0.1.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio==3.23->llava==0.1.0) (2024.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.23->llava==0.1.0) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.23->llava==0.1.0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.23->llava==0.1.0) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.23->llava==0.1.0) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.23->llava==0.1.0) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.23->llava==0.1.0) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.23->llava==0.1.0) (4.0.3)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.23->llava==0.1.0) (0.17.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.23->llava==0.1.0) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.23->llava==0.1.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.23->llava==0.1.0) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.23->llava==0.1.0) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib->gradio==3.23->llava==0.1.0) (2.4.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->llava==0.1.0) (1.3.0)\n",
      "Requirement already satisfied: svgwrite in /usr/local/lib/python3.10/dist-packages (from wavedrom->markdown2[all]->llava==0.1.0) (1.4.3)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->llava==0.1.0) (5.0.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.23->llava==0.1.0) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.23->llava==0.1.0) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.23->llava==0.1.0) (0.12.0)\n",
      "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio==3.23->llava==0.1.0) (1.0.3)\n",
      "Using cached tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "Building wheels for collected packages: llava\n",
      "  Building editable for llava (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for llava: filename=llava-0.1.0-0.editable-py3-none-any.whl size=15524 sha256=4e81e759368ff520bb63cc7a9e4693151c8851b4531aecc6c7c371c98c292ad5\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ydqbrfrp/wheels/93/d1/c3/01b97c03262c7aa30d33cb8bacd52c3296853d2c1317b5f114\n",
      "Successfully built llava\n",
      "Installing collected packages: tokenizers, llava\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.3\n",
      "    Uninstalling tokenizers-0.13.3:\n",
      "      Successfully uninstalled tokenizers-0.13.3\n",
      "  Attempting uninstall: llava\n",
      "    Found existing installation: llava 0.1.0\n",
      "    Uninstalling llava-0.1.0:\n",
      "      Successfully uninstalled llava-0.1.0\n",
      "Successfully installed llava-0.1.0 tokenizers-0.12.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall torch torchvision -y\n",
    "!pip install torch==2.0.0+cu117 torchvision==0.15.1+cu117 torchaudio==2.0.1 --index-url https://download.pytorch.org/whl/cu117\n",
    "!pip install openai==0.27.8\n",
    "!pip uninstall transformers -y\n",
    "!pip install git+https://github.com/huggingface/transformers@cae78c46\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "Go6nxgvLBc7d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33305,
     "status": "ok",
     "timestamp": 1721611230578,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 420
    },
    "id": "Go6nxgvLBc7d",
    "outputId": "6b703659-f190-42a4-8b8c-88fe843befaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
      "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (1.11.1.1)\n",
      "Requirement already satisfied: open-clip-torch in /usr/local/lib/python3.10/dist-packages (2.26.1)\n",
      "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from open-clip-torch) (2.0.0+cu117)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from open-clip-torch) (0.15.1+cu117)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from open-clip-torch) (2024.7.24)\n",
      "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from open-clip-torch) (6.2.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from open-clip-torch) (4.66.5)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from open-clip-torch) (0.24.6)\n",
      "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from open-clip-torch) (0.6.13)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open-clip-torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open-clip-torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open-clip-torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open-clip-torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open-clip-torch) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open-clip-torch) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9.0->open-clip-torch) (3.25.0)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.9.0->open-clip-torch) (15.0.7)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->open-clip-torch) (0.2.13)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open-clip-torch) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open-clip-torch) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open-clip-torch) (6.0.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open-clip-torch) (2.32.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->open-clip-torch) (1.24.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->open-clip-torch) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->open-clip-torch) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open-clip-torch) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open-clip-torch) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open-clip-torch) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open-clip-torch) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.0->open-clip-torch) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: flash-attn 2.6.3\n",
      "Uninstalling flash-attn-2.6.3:\n",
      "  Would remove:\n",
      "    /usr/local/lib/python3.10/dist-packages/flash_attn-2.6.3.dist-info/*\n",
      "    /usr/local/lib/python3.10/dist-packages/flash_attn/*\n",
      "    /usr/local/lib/python3.10/dist-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so\n",
      "    /usr/local/lib/python3.10/dist-packages/hopper/*\n",
      "Proceed (Y/n)?   Successfully uninstalled flash-attn-2.6.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting flash-attn\n",
      "  Downloading flash_attn-2.6.3.tar.gz (2.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m183.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash-attn) (2.0.0+cu117)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from flash-attn) (0.6.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->flash-attn) (3.25.0)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->flash-attn) (15.0.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash-attn) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->flash-attn) (1.3.0)\n",
      "Building wheels for collected packages: flash-attn\n",
      "  Building wheel for flash-attn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for flash-attn: filename=flash_attn-2.6.3-cp310-cp310-linux_x86_64.whl size=188930485 sha256=f242b686e89e4bd88474ac4ceb7a5b19d738b4e63e2132f50edd7b6f397f8654\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-j4qh9d2c/wheels/7e/e3/c3/89c7a2f3c4adc07cd1c675f8bb7b9ad4d18f64a72bccdfe826\n",
      "Successfully built flash-attn\n",
      "Installing collected packages: flash-attn\n",
      "Successfully installed flash-attn-2.6.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install einops ninja open-clip-torch\n",
    "!echo Y | pip uninstall flash-attn\n",
    "!pip install flash-attn --no-build-isolation --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "21b29e4a-fd46-403e-b31a-b6b0eb1d2f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected operating system as Ubuntu/jammy.\n",
      "Checking for curl...\n",
      "Detected curl...\n",
      "Checking for gpg...\n",
      "Detected gpg...\n",
      "Detected apt version as 2.4.10\n",
      "Running apt-get update... done.\n",
      "Installing apt-transport-https... done.\n",
      "Installing /etc/apt/sources.list.d/github_git-lfs.list...done.\n",
      "Importing packagecloud gpg key... Packagecloud gpg key imported to /etc/apt/keyrings/github_git-lfs-archive-keyring.gpg\n",
      "done.\n",
      "Running apt-get update... done.\n",
      "\n",
      "The repository is setup! You can now install packages.\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "git-lfs is already the newest version (3.5.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 97 not upgraded.\n",
      "Updated Git hooks.\n",
      "Git LFS initialized.\n"
     ]
    }
   ],
   "source": [
    "!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | bash\n",
    "!apt-get install git-lfs\n",
    "!git lfs install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "qnDM6N3yB-i1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 240988,
     "status": "ok",
     "timestamp": 1721611559143,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 420
    },
    "id": "qnDM6N3yB-i1",
    "outputId": "7bf645a9-90a3-47b2-80a8-4f2937006c3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'llava-med-7b-delta'...\n",
      "remote: Enumerating objects: 69, done.\u001b[K\n",
      "remote: Counting objects: 100% (65/65), done.\u001b[K\n",
      "remote: Compressing objects: 100% (65/65), done.\u001b[K\n",
      "remote: Total 69 (delta 27), reused 0 (delta 0), pack-reused 4 (from 1)\u001b[K\n",
      "Unpacking objects: 100% (69/69), 47.24 KiB | 165.00 KiB/s, done.\n",
      "Filtering content: 100% (3/3), 4.55 GiB | 12.16 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://huggingface.co/microsoft/llava-med-7b-delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "wPpmbQpVCDyC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1417244,
     "status": "ok",
     "timestamp": 1721612976385,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 420
    },
    "id": "wPpmbQpVCDyC",
    "outputId": "ae1b5250-d649-447f-89df-e3abc0b0ba37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'llama-7b'...\n",
      "remote: Enumerating objects: 31, done.\u001b[K\n",
      "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
      "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
      "remote: Total 31 (delta 5), reused 3 (delta 3), pack-reused 22 (from 1)\u001b[K\n",
      "Unpacking objects: 100% (31/31), 489.40 KiB | 1.51 MiB/s, done.\n",
      "Filtering content: 100% (5/5), 9.10 GiB | 14.43 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://huggingface.co/huggyllama/llama-7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "s_aktOR1DMAc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 867342,
     "status": "ok",
     "timestamp": 1721613844497,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 420
    },
    "id": "s_aktOR1DMAc",
    "outputId": "bc1fe08c-6a36-4924-8c03-7fd80e684ac5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-21 21:49:42,714] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Loading base model\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:01<00:00,  1.36it/s]\n",
      "Loading delta\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at openai/clip-vit-large-patch14 were not used when initializing CLIPVisionModel: ['text_model.encoder.layers.7.self_attn.q_proj.bias', 'text_model.encoder.layers.8.self_attn.v_proj.bias', 'text_model.encoder.layers.3.self_attn.v_proj.bias', 'text_model.encoder.layers.5.mlp.fc1.weight', 'text_model.encoder.layers.1.mlp.fc2.bias', 'text_model.encoder.layers.3.self_attn.q_proj.bias', 'text_model.encoder.layers.11.self_attn.k_proj.bias', 'text_model.encoder.layers.8.mlp.fc1.bias', 'text_model.encoder.layers.4.layer_norm1.weight', 'text_model.encoder.layers.1.self_attn.q_proj.bias', 'text_model.encoder.layers.1.self_attn.v_proj.bias', 'text_model.encoder.layers.3.mlp.fc2.weight', 'text_model.encoder.layers.9.layer_norm1.bias', 'text_model.encoder.layers.9.layer_norm2.bias', 'text_model.encoder.layers.11.self_attn.k_proj.weight', 'text_model.encoder.layers.1.layer_norm1.weight', 'text_model.encoder.layers.7.self_attn.k_proj.bias', 'text_model.encoder.layers.8.self_attn.out_proj.weight', 'text_model.encoder.layers.2.layer_norm2.weight', 'text_model.encoder.layers.6.layer_norm2.bias', 'text_model.encoder.layers.0.layer_norm1.weight', 'text_model.encoder.layers.8.self_attn.v_proj.weight', 'text_model.encoder.layers.10.self_attn.v_proj.bias', 'text_model.encoder.layers.10.layer_norm1.weight', 'text_model.encoder.layers.4.layer_norm2.weight', 'text_model.encoder.layers.5.layer_norm2.bias', 'text_model.encoder.layers.11.self_attn.out_proj.weight', 'text_model.encoder.layers.8.self_attn.k_proj.bias', 'text_model.encoder.layers.9.layer_norm1.weight', 'text_model.encoder.layers.10.self_attn.k_proj.bias', 'text_model.encoder.layers.10.self_attn.v_proj.weight', 'text_model.encoder.layers.1.mlp.fc1.bias', 'text_model.encoder.layers.6.self_attn.q_proj.bias', 'text_model.encoder.layers.4.self_attn.out_proj.weight', 'text_model.encoder.layers.9.self_attn.q_proj.weight', 'text_model.encoder.layers.8.layer_norm2.weight', 'text_model.encoder.layers.6.self_attn.k_proj.weight', 'text_model.encoder.layers.11.mlp.fc1.weight', 'text_model.encoder.layers.9.layer_norm2.weight', 'text_model.encoder.layers.2.mlp.fc1.bias', 'text_model.encoder.layers.8.layer_norm1.bias', 'text_model.encoder.layers.4.self_attn.q_proj.weight', 'text_model.encoder.layers.0.mlp.fc1.bias', 'text_model.encoder.layers.9.self_attn.v_proj.bias', 'text_model.encoder.layers.7.self_attn.v_proj.bias', 'text_model.encoder.layers.6.self_attn.v_proj.bias', 'visual_projection.weight', 'text_model.encoder.layers.0.self_attn.v_proj.weight', 'text_model.final_layer_norm.weight', 'text_model.encoder.layers.3.mlp.fc2.bias', 'text_model.encoder.layers.9.mlp.fc2.weight', 'text_model.encoder.layers.9.self_attn.out_proj.bias', 'text_model.encoder.layers.0.self_attn.out_proj.weight', 'text_model.encoder.layers.10.self_attn.q_proj.weight', 'text_model.encoder.layers.9.mlp.fc2.bias', 'text_model.encoder.layers.6.layer_norm2.weight', 'text_model.encoder.layers.7.self_attn.q_proj.weight', 'text_model.encoder.layers.4.layer_norm2.bias', 'text_model.encoder.layers.7.mlp.fc2.bias', 'text_model.encoder.layers.11.layer_norm1.weight', 'text_model.encoder.layers.6.mlp.fc2.weight', 'text_model.encoder.layers.3.self_attn.q_proj.weight', 'text_model.encoder.layers.2.self_attn.k_proj.weight', 'text_model.encoder.layers.5.mlp.fc2.weight', 'text_model.encoder.layers.11.self_attn.v_proj.bias', 'text_model.encoder.layers.4.self_attn.k_proj.weight', 'text_model.encoder.layers.2.self_attn.out_proj.weight', 'text_model.encoder.layers.11.mlp.fc2.weight', 'text_model.encoder.layers.11.layer_norm2.weight', 'text_model.encoder.layers.4.self_attn.v_proj.weight', 'text_model.encoder.layers.2.self_attn.q_proj.bias', 'text_model.encoder.layers.4.mlp.fc1.weight', 'text_model.encoder.layers.4.mlp.fc2.bias', 'text_model.encoder.layers.6.self_attn.v_proj.weight', 'text_model.encoder.layers.2.self_attn.k_proj.bias', 'text_model.encoder.layers.5.self_attn.v_proj.bias', 'logit_scale', 'text_model.encoder.layers.5.layer_norm1.weight', 'text_model.encoder.layers.5.self_attn.out_proj.bias', 'text_model.encoder.layers.5.self_attn.q_proj.bias', 'text_model.encoder.layers.11.mlp.fc1.bias', 'text_model.encoder.layers.7.self_attn.out_proj.bias', 'text_model.encoder.layers.3.layer_norm1.weight', 'text_model.final_layer_norm.bias', 'text_model.encoder.layers.3.self_attn.out_proj.bias', 'text_model.encoder.layers.0.self_attn.v_proj.bias', 'text_model.encoder.layers.2.self_attn.out_proj.bias', 'text_model.encoder.layers.10.self_attn.k_proj.weight', 'text_model.encoder.layers.5.mlp.fc1.bias', 'text_model.encoder.layers.1.mlp.fc1.weight', 'text_model.encoder.layers.1.self_attn.v_proj.weight', 'text_model.encoder.layers.10.self_attn.out_proj.weight', 'text_model.encoder.layers.1.self_attn.out_proj.weight', 'text_model.encoder.layers.0.layer_norm1.bias', 'text_model.encoder.layers.9.mlp.fc1.bias', 'text_model.encoder.layers.6.self_attn.out_proj.bias', 'text_model.encoder.layers.0.layer_norm2.bias', 'text_model.encoder.layers.7.layer_norm1.bias', 'text_model.encoder.layers.10.mlp.fc2.bias', 'text_model.encoder.layers.7.self_attn.v_proj.weight', 'text_model.encoder.layers.3.self_attn.k_proj.weight', 'text_model.encoder.layers.7.self_attn.out_proj.weight', 'text_model.encoder.layers.1.self_attn.k_proj.weight', 'text_model.encoder.layers.0.mlp.fc1.weight', 'text_model.encoder.layers.10.layer_norm2.bias', 'text_model.encoder.layers.2.mlp.fc1.weight', 'text_model.encoder.layers.11.layer_norm1.bias', 'text_model.encoder.layers.0.self_attn.out_proj.bias', 'text_model.encoder.layers.7.mlp.fc1.bias', 'text_model.encoder.layers.9.self_attn.q_proj.bias', 'text_model.encoder.layers.3.mlp.fc1.weight', 'text_model.encoder.layers.6.mlp.fc1.weight', 'text_model.encoder.layers.4.self_attn.k_proj.bias', 'text_model.encoder.layers.6.layer_norm1.weight', 'text_model.encoder.layers.6.self_attn.q_proj.weight', 'text_model.encoder.layers.9.self_attn.k_proj.weight', 'text_model.encoder.layers.0.self_attn.k_proj.bias', 'text_model.encoder.layers.8.self_attn.k_proj.weight', 'text_model.encoder.layers.0.self_attn.k_proj.weight', 'text_model.encoder.layers.8.mlp.fc2.weight', 'text_model.encoder.layers.8.self_attn.out_proj.bias', 'text_model.encoder.layers.6.mlp.fc1.bias', 'text_model.encoder.layers.8.layer_norm1.weight', 'text_model.encoder.layers.10.self_attn.out_proj.bias', 'text_model.embeddings.position_embedding.weight', 'text_model.encoder.layers.1.self_attn.q_proj.weight', 'text_model.encoder.layers.7.mlp.fc2.weight', 'text_projection.weight', 'text_model.encoder.layers.1.layer_norm2.bias', 'text_model.encoder.layers.6.layer_norm1.bias', 'text_model.encoder.layers.5.self_attn.v_proj.weight', 'text_model.encoder.layers.7.layer_norm2.weight', 'text_model.encoder.layers.2.layer_norm1.bias', 'text_model.encoder.layers.8.self_attn.q_proj.bias', 'text_model.encoder.layers.4.self_attn.out_proj.bias', 'text_model.encoder.layers.5.self_attn.k_proj.bias', 'text_model.encoder.layers.1.mlp.fc2.weight', 'text_model.encoder.layers.11.self_attn.q_proj.weight', 'text_model.encoder.layers.2.self_attn.q_proj.weight', 'text_model.encoder.layers.10.layer_norm2.weight', 'text_model.encoder.layers.3.layer_norm2.weight', 'text_model.encoder.layers.8.self_attn.q_proj.weight', 'text_model.encoder.layers.2.self_attn.v_proj.weight', 'text_model.encoder.layers.4.mlp.fc1.bias', 'text_model.encoder.layers.11.mlp.fc2.bias', 'text_model.encoder.layers.8.mlp.fc2.bias', 'text_model.encoder.layers.4.self_attn.q_proj.bias', 'text_model.encoder.layers.10.self_attn.q_proj.bias', 'text_model.encoder.layers.11.self_attn.q_proj.bias', 'text_model.encoder.layers.9.self_attn.out_proj.weight', 'text_model.encoder.layers.3.self_attn.v_proj.weight', 'text_model.encoder.layers.3.self_attn.k_proj.bias', 'text_model.encoder.layers.3.layer_norm1.bias', 'text_model.encoder.layers.0.self_attn.q_proj.bias', 'text_model.encoder.layers.7.self_attn.k_proj.weight', 'text_model.encoder.layers.6.self_attn.k_proj.bias', 'text_model.encoder.layers.2.layer_norm2.bias', 'text_model.encoder.layers.2.self_attn.v_proj.bias', 'text_model.encoder.layers.1.self_attn.k_proj.bias', 'text_model.encoder.layers.10.mlp.fc2.weight', 'text_model.encoder.layers.2.mlp.fc2.weight', 'text_model.embeddings.position_ids', 'text_model.encoder.layers.5.layer_norm2.weight', 'text_model.encoder.layers.3.self_attn.out_proj.weight', 'text_model.encoder.layers.2.layer_norm1.weight', 'text_model.encoder.layers.11.self_attn.v_proj.weight', 'text_model.encoder.layers.8.layer_norm2.bias', 'text_model.encoder.layers.9.self_attn.k_proj.bias', 'text_model.encoder.layers.7.layer_norm2.bias', 'text_model.encoder.layers.10.mlp.fc1.weight', 'text_model.encoder.layers.11.layer_norm2.bias', 'text_model.encoder.layers.0.mlp.fc2.bias', 'text_model.encoder.layers.5.self_attn.q_proj.weight', 'text_model.encoder.layers.1.self_attn.out_proj.bias', 'text_model.encoder.layers.0.layer_norm2.weight', 'text_model.encoder.layers.7.mlp.fc1.weight', 'text_model.encoder.layers.0.self_attn.q_proj.weight', 'text_model.encoder.layers.6.mlp.fc2.bias', 'text_model.encoder.layers.4.layer_norm1.bias', 'text_model.encoder.layers.10.layer_norm1.bias', 'text_model.encoder.layers.1.layer_norm1.bias', 'text_model.encoder.layers.5.mlp.fc2.bias', 'text_model.encoder.layers.8.mlp.fc1.weight', 'text_model.encoder.layers.5.self_attn.out_proj.weight', 'text_model.encoder.layers.9.self_attn.v_proj.weight', 'text_model.encoder.layers.3.mlp.fc1.bias', 'text_model.encoder.layers.5.layer_norm1.bias', 'text_model.encoder.layers.10.mlp.fc1.bias', 'text_model.encoder.layers.2.mlp.fc2.bias', 'text_model.encoder.layers.3.layer_norm2.bias', 'text_model.embeddings.token_embedding.weight', 'text_model.encoder.layers.11.self_attn.out_proj.bias', 'text_model.encoder.layers.9.mlp.fc1.weight', 'text_model.encoder.layers.6.self_attn.out_proj.weight', 'text_model.encoder.layers.1.layer_norm2.weight', 'text_model.encoder.layers.7.layer_norm1.weight', 'text_model.encoder.layers.4.self_attn.v_proj.bias', 'text_model.encoder.layers.0.mlp.fc2.weight', 'text_model.encoder.layers.4.mlp.fc2.weight', 'text_model.encoder.layers.5.self_attn.k_proj.weight']\n",
      "- This IS expected if you are initializing CLIPVisionModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CLIPVisionModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:20<00:00, 10.10s/it]\n",
      "Applying delta\n",
      "Applying delta: 100%|█████████████████████████| 325/325 [01:07<00:00,  4.83it/s]\n",
      "Saving target model\n"
     ]
    }
   ],
   "source": [
    "!python3 -m llava.model.apply_delta \\\n",
    "    --base '/workspace/LLaVA-Med/Model/LLaVA-Med-Retina/llama-7b' \\\n",
    "    --target '/workspace/LLaVA-Med/Model/LLaVA-7b-v0' \\\n",
    "    --delta '/workspace/LLaVA-Med/Model/LLaVA-Med-Retina/llava-med-7b-delta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e209fb04-ad4a-4dd1-acd3-330c608e0af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['WANDB_DISABLED'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd949d10-88c8-403b-b55b-e6657c230ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/LLaVA-Med/Model/LLaVA-Med-Retina'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e576d448-efae-40ec-9040-e10eadb0046d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-21 21:54:00,800] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at openai/clip-vit-large-patch14 were not used when initializing CLIPVisionModel: ['text_model.encoder.layers.0.mlp.fc2.bias', 'text_model.encoder.layers.10.self_attn.q_proj.weight', 'text_model.encoder.layers.11.mlp.fc1.weight', 'text_model.encoder.layers.7.self_attn.k_proj.bias', 'text_model.encoder.layers.10.self_attn.v_proj.weight', 'text_model.encoder.layers.2.self_attn.v_proj.weight', 'text_model.encoder.layers.4.layer_norm2.bias', 'text_model.encoder.layers.11.self_attn.out_proj.bias', 'text_model.encoder.layers.11.self_attn.k_proj.bias', 'text_model.encoder.layers.10.self_attn.q_proj.bias', 'text_model.encoder.layers.8.self_attn.k_proj.bias', 'text_model.encoder.layers.0.layer_norm1.weight', 'visual_projection.weight', 'text_model.encoder.layers.3.layer_norm1.weight', 'text_model.encoder.layers.7.mlp.fc2.bias', 'text_model.encoder.layers.5.self_attn.k_proj.weight', 'text_model.encoder.layers.6.layer_norm2.bias', 'text_model.encoder.layers.7.self_attn.v_proj.weight', 'text_model.encoder.layers.8.layer_norm1.bias', 'text_model.encoder.layers.1.mlp.fc2.weight', 'text_model.encoder.layers.2.self_attn.q_proj.bias', 'text_model.encoder.layers.5.self_attn.v_proj.bias', 'text_model.encoder.layers.3.self_attn.out_proj.bias', 'text_model.encoder.layers.0.self_attn.q_proj.bias', 'text_model.encoder.layers.5.self_attn.k_proj.bias', 'text_model.encoder.layers.3.self_attn.k_proj.bias', 'text_model.encoder.layers.7.layer_norm1.bias', 'text_model.encoder.layers.3.self_attn.v_proj.weight', 'text_model.encoder.layers.4.layer_norm1.bias', 'text_model.encoder.layers.1.self_attn.q_proj.bias', 'text_model.encoder.layers.10.layer_norm2.bias', 'text_model.encoder.layers.9.mlp.fc1.bias', 'text_model.encoder.layers.2.mlp.fc2.bias', 'text_model.encoder.layers.0.mlp.fc2.weight', 'text_model.encoder.layers.9.mlp.fc2.weight', 'text_model.encoder.layers.8.self_attn.k_proj.weight', 'text_model.encoder.layers.5.mlp.fc1.bias', 'text_model.encoder.layers.4.self_attn.out_proj.weight', 'text_model.encoder.layers.11.layer_norm2.weight', 'text_model.embeddings.position_embedding.weight', 'text_model.encoder.layers.8.self_attn.out_proj.bias', 'text_model.encoder.layers.4.mlp.fc2.weight', 'text_model.encoder.layers.11.mlp.fc2.bias', 'text_model.encoder.layers.11.layer_norm2.bias', 'text_model.encoder.layers.1.mlp.fc2.bias', 'text_model.encoder.layers.9.layer_norm2.weight', 'text_model.encoder.layers.9.layer_norm1.bias', 'text_model.encoder.layers.1.mlp.fc1.bias', 'text_model.encoder.layers.1.layer_norm2.bias', 'text_model.encoder.layers.4.mlp.fc1.weight', 'text_model.encoder.layers.6.mlp.fc1.bias', 'text_model.encoder.layers.7.self_attn.out_proj.weight', 'text_model.encoder.layers.1.self_attn.v_proj.weight', 'text_model.encoder.layers.7.self_attn.out_proj.bias', 'text_model.encoder.layers.0.self_attn.v_proj.weight', 'text_model.encoder.layers.3.self_attn.q_proj.weight', 'text_model.encoder.layers.2.self_attn.v_proj.bias', 'text_model.encoder.layers.11.layer_norm1.weight', 'text_model.encoder.layers.0.layer_norm2.weight', 'text_model.encoder.layers.4.self_attn.k_proj.weight', 'text_model.encoder.layers.4.self_attn.out_proj.bias', 'text_model.encoder.layers.10.self_attn.out_proj.weight', 'text_model.encoder.layers.0.layer_norm1.bias', 'text_model.encoder.layers.6.mlp.fc2.bias', 'text_model.encoder.layers.3.layer_norm1.bias', 'text_model.encoder.layers.1.self_attn.v_proj.bias', 'text_model.encoder.layers.0.mlp.fc1.bias', 'text_model.encoder.layers.7.mlp.fc1.bias', 'text_model.encoder.layers.8.layer_norm1.weight', 'text_model.encoder.layers.1.layer_norm1.weight', 'text_model.encoder.layers.11.self_attn.v_proj.bias', 'text_model.encoder.layers.10.mlp.fc1.bias', 'text_model.encoder.layers.4.mlp.fc1.bias', 'text_model.encoder.layers.6.layer_norm2.weight', 'text_model.encoder.layers.7.mlp.fc2.weight', 'text_model.encoder.layers.0.self_attn.out_proj.weight', 'text_model.encoder.layers.6.self_attn.k_proj.bias', 'text_model.encoder.layers.4.self_attn.k_proj.bias', 'text_model.encoder.layers.2.mlp.fc1.bias', 'text_model.encoder.layers.9.layer_norm2.bias', 'text_model.encoder.layers.8.layer_norm2.weight', 'text_model.encoder.layers.1.self_attn.out_proj.bias', 'text_model.encoder.layers.10.layer_norm1.weight', 'text_model.encoder.layers.7.self_attn.k_proj.weight', 'text_model.encoder.layers.10.layer_norm2.weight', 'text_model.encoder.layers.6.layer_norm1.weight', 'text_model.encoder.layers.8.self_attn.q_proj.bias', 'text_projection.weight', 'text_model.encoder.layers.7.self_attn.q_proj.bias', 'text_model.encoder.layers.7.self_attn.q_proj.weight', 'text_model.encoder.layers.6.self_attn.v_proj.bias', 'text_model.encoder.layers.6.self_attn.q_proj.weight', 'text_model.encoder.layers.0.mlp.fc1.weight', 'text_model.encoder.layers.0.self_attn.out_proj.bias', 'text_model.encoder.layers.3.mlp.fc2.weight', 'text_model.encoder.layers.9.self_attn.q_proj.bias', 'text_model.encoder.layers.2.self_attn.k_proj.weight', 'text_model.encoder.layers.2.layer_norm2.bias', 'text_model.encoder.layers.1.mlp.fc1.weight', 'text_model.encoder.layers.1.self_attn.out_proj.weight', 'text_model.encoder.layers.10.mlp.fc2.weight', 'text_model.encoder.layers.2.mlp.fc1.weight', 'text_model.encoder.layers.9.mlp.fc1.weight', 'text_model.embeddings.token_embedding.weight', 'text_model.encoder.layers.4.layer_norm1.weight', 'text_model.encoder.layers.10.self_attn.v_proj.bias', 'text_model.encoder.layers.7.layer_norm2.bias', 'text_model.encoder.layers.8.self_attn.v_proj.weight', 'text_model.encoder.layers.11.self_attn.v_proj.weight', 'text_model.encoder.layers.4.mlp.fc2.bias', 'text_model.encoder.layers.7.layer_norm1.weight', 'text_model.encoder.layers.3.mlp.fc2.bias', 'text_model.encoder.layers.10.self_attn.k_proj.bias', 'text_model.encoder.layers.9.self_attn.k_proj.weight', 'text_model.encoder.layers.10.layer_norm1.bias', 'text_model.encoder.layers.5.layer_norm1.weight', 'text_model.encoder.layers.0.self_attn.v_proj.bias', 'text_model.encoder.layers.10.mlp.fc1.weight', 'text_model.encoder.layers.2.self_attn.out_proj.bias', 'text_model.encoder.layers.6.self_attn.out_proj.weight', 'text_model.encoder.layers.3.self_attn.out_proj.weight', 'text_model.encoder.layers.3.layer_norm2.weight', 'text_model.encoder.layers.11.mlp.fc2.weight', 'text_model.encoder.layers.1.self_attn.k_proj.weight', 'text_model.encoder.layers.8.self_attn.out_proj.weight', 'text_model.encoder.layers.6.self_attn.q_proj.bias', 'text_model.encoder.layers.9.self_attn.k_proj.bias', 'text_model.encoder.layers.4.self_attn.v_proj.bias', 'text_model.encoder.layers.5.mlp.fc2.bias', 'text_model.encoder.layers.5.self_attn.out_proj.bias', 'text_model.encoder.layers.5.mlp.fc1.weight', 'text_model.encoder.layers.5.self_attn.out_proj.weight', 'text_model.encoder.layers.9.layer_norm1.weight', 'text_model.encoder.layers.10.self_attn.out_proj.bias', 'text_model.encoder.layers.11.self_attn.q_proj.bias', 'text_model.encoder.layers.4.layer_norm2.weight', 'text_model.encoder.layers.9.self_attn.q_proj.weight', 'text_model.encoder.layers.11.layer_norm1.bias', 'text_model.encoder.layers.6.mlp.fc1.weight', 'text_model.encoder.layers.9.mlp.fc2.bias', 'text_model.encoder.layers.0.self_attn.k_proj.bias', 'text_model.encoder.layers.6.self_attn.v_proj.weight', 'text_model.encoder.layers.0.layer_norm2.bias', 'text_model.encoder.layers.1.layer_norm2.weight', 'text_model.encoder.layers.5.layer_norm2.weight', 'text_model.encoder.layers.3.mlp.fc1.bias', 'text_model.encoder.layers.8.mlp.fc2.bias', 'text_model.encoder.layers.3.layer_norm2.bias', 'text_model.encoder.layers.5.layer_norm1.bias', 'text_model.encoder.layers.2.self_attn.out_proj.weight', 'text_model.encoder.layers.0.self_attn.q_proj.weight', 'text_model.encoder.layers.1.self_attn.k_proj.bias', 'logit_scale', 'text_model.encoder.layers.9.self_attn.v_proj.weight', 'text_model.encoder.layers.3.self_attn.k_proj.weight', 'text_model.encoder.layers.7.self_attn.v_proj.bias', 'text_model.final_layer_norm.weight', 'text_model.encoder.layers.7.layer_norm2.weight', 'text_model.encoder.layers.8.mlp.fc1.weight', 'text_model.encoder.layers.8.mlp.fc2.weight', 'text_model.encoder.layers.10.self_attn.k_proj.weight', 'text_model.encoder.layers.4.self_attn.v_proj.weight', 'text_model.encoder.layers.5.self_attn.q_proj.weight', 'text_model.encoder.layers.9.self_attn.out_proj.weight', 'text_model.encoder.layers.4.self_attn.q_proj.bias', 'text_model.encoder.layers.2.layer_norm2.weight', 'text_model.encoder.layers.6.mlp.fc2.weight', 'text_model.embeddings.position_ids', 'text_model.encoder.layers.11.self_attn.q_proj.weight', 'text_model.encoder.layers.3.mlp.fc1.weight', 'text_model.encoder.layers.5.mlp.fc2.weight', 'text_model.encoder.layers.10.mlp.fc2.bias', 'text_model.encoder.layers.5.layer_norm2.bias', 'text_model.encoder.layers.1.self_attn.q_proj.weight', 'text_model.encoder.layers.8.layer_norm2.bias', 'text_model.encoder.layers.11.mlp.fc1.bias', 'text_model.encoder.layers.6.layer_norm1.bias', 'text_model.encoder.layers.0.self_attn.k_proj.weight', 'text_model.encoder.layers.9.self_attn.v_proj.bias', 'text_model.final_layer_norm.bias', 'text_model.encoder.layers.2.layer_norm1.weight', 'text_model.encoder.layers.6.self_attn.k_proj.weight', 'text_model.encoder.layers.5.self_attn.v_proj.weight', 'text_model.encoder.layers.2.layer_norm1.bias', 'text_model.encoder.layers.6.self_attn.out_proj.bias', 'text_model.encoder.layers.8.mlp.fc1.bias', 'text_model.encoder.layers.11.self_attn.k_proj.weight', 'text_model.encoder.layers.2.self_attn.q_proj.weight', 'text_model.encoder.layers.4.self_attn.q_proj.weight', 'text_model.encoder.layers.3.self_attn.q_proj.bias', 'text_model.encoder.layers.5.self_attn.q_proj.bias', 'text_model.encoder.layers.2.mlp.fc2.weight', 'text_model.encoder.layers.3.self_attn.v_proj.bias', 'text_model.encoder.layers.1.layer_norm1.bias', 'text_model.encoder.layers.9.self_attn.out_proj.bias', 'text_model.encoder.layers.2.self_attn.k_proj.bias', 'text_model.encoder.layers.11.self_attn.out_proj.weight', 'text_model.encoder.layers.7.mlp.fc1.weight', 'text_model.encoder.layers.8.self_attn.v_proj.bias', 'text_model.encoder.layers.8.self_attn.q_proj.weight']\n",
      "- This IS expected if you are initializing CLIPVisionModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CLIPVisionModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:24<00:00, 12.01s/it]\n",
      "WARNING:root:Loading data...\n",
      "WARNING:root:Formatting inputs...Skip in lazy mode\n",
      "{'loss': 1.2665, 'learning_rate': 0.00025, 'epoch': 0.07}                       \n",
      "{'loss': 1.2661, 'learning_rate': 0.0005, 'epoch': 0.13}                        \n",
      "{'loss': 1.2718, 'learning_rate': 0.00075, 'epoch': 0.2}                        \n",
      "{'loss': 1.1898, 'learning_rate': 0.001, 'epoch': 0.27}                         \n",
      "{'loss': 1.2123, 'learning_rate': 0.00125, 'epoch': 0.33}                       \n",
      "{'loss': 1.1084, 'learning_rate': 0.0015, 'epoch': 0.4}                         \n",
      "{'loss': 1.0819, 'learning_rate': 0.00175, 'epoch': 0.47}                       \n",
      "{'loss': 1.1255, 'learning_rate': 0.002, 'epoch': 0.53}                         \n",
      "{'loss': 1.0739, 'learning_rate': 0.001999908317352967, 'epoch': 0.6}           \n",
      "{'loss': 0.9957, 'learning_rate': 0.001999633286223284, 'epoch': 0.67}          \n",
      "{'loss': 0.8743, 'learning_rate': 0.0019991749570421147, 'epoch': 0.73}         \n",
      "{'loss': 0.9117, 'learning_rate': 0.0019985334138511238, 'epoch': 0.8}          \n",
      "{'loss': 0.9207, 'learning_rate': 0.001997708774287068, 'epoch': 0.87}          \n",
      "{'loss': 0.9185, 'learning_rate': 0.001996701189560223, 'epoch': 0.93}          \n",
      "{'loss': 0.7966, 'learning_rate': 0.001995510844426658, 'epoch': 1.0}           \n",
      "{'loss': 0.706, 'learning_rate': 0.0019941379571543597, 'epoch': 1.07}          \n",
      "{'loss': 0.7552, 'learning_rate': 0.0019925827794832055, 'epoch': 1.13}         \n",
      "{'loss': 0.5848, 'learning_rate': 0.001990845596578807, 'epoch': 1.2}           \n",
      "{'loss': 0.6869, 'learning_rate': 0.0019889267269802176, 'epoch': 1.27}         \n",
      "{'loss': 0.709, 'learning_rate': 0.0019868265225415262, 'epoch': 1.33}          \n",
      "{'loss': 0.6056, 'learning_rate': 0.001984545368367337, 'epoch': 1.4}           \n",
      "{'loss': 0.6102, 'learning_rate': 0.001982083682742156, 'epoch': 1.47}          \n",
      "{'loss': 0.5636, 'learning_rate': 0.001979441917053692, 'epoch': 1.53}          \n",
      "{'loss': 0.6094, 'learning_rate': 0.0019766205557100866, 'epoch': 1.6}          \n",
      "{'loss': 0.5263, 'learning_rate': 0.0019736201160510934, 'epoch': 1.67}         \n",
      "{'loss': 0.5727, 'learning_rate': 0.001970441148253211, 'epoch': 1.73}          \n",
      "{'loss': 0.5916, 'learning_rate': 0.001967084235228807, 'epoch': 1.8}           \n",
      "{'loss': 0.5103, 'learning_rate': 0.001963549992519223, 'epoch': 1.87}          \n",
      "{'loss': 0.506, 'learning_rate': 0.001959839068181914, 'epoch': 1.93}           \n",
      "{'loss': 0.7986, 'learning_rate': 0.001955952142671612, 'epoch': 2.0}           \n",
      "{'loss': 0.3776, 'learning_rate': 0.0019518899287155557, 'epoch': 2.07}         \n",
      "{'loss': 0.3735, 'learning_rate': 0.0019476531711828025, 'epoch': 2.13}         \n",
      "{'loss': 0.3601, 'learning_rate': 0.001943242646947643, 'epoch': 2.2}           \n",
      "{'loss': 0.4659, 'learning_rate': 0.0019386591647471505, 'epoch': 2.27}         \n",
      "{'loss': 0.4211, 'learning_rate': 0.0019339035650328866, 'epoch': 2.33}         \n",
      "{'loss': 0.3792, 'learning_rate': 0.0019289767198167917, 'epoch': 2.4}          \n",
      "{'loss': 0.308, 'learning_rate': 0.0019238795325112869, 'epoch': 2.47}          \n",
      "{'loss': 0.3275, 'learning_rate': 0.0019186129377636218, 'epoch': 2.53}         \n",
      "{'loss': 0.3991, 'learning_rate': 0.0019131779012844911, 'epoch': 2.6}          \n",
      "{'loss': 0.4608, 'learning_rate': 0.0019075754196709572, 'epoch': 2.67}         \n",
      "{'loss': 0.3076, 'learning_rate': 0.0019018065202237083, 'epoch': 2.73}         \n",
      "{'loss': 0.4813, 'learning_rate': 0.001895872260758688, 'epoch': 2.8}           \n",
      "{'loss': 0.3855, 'learning_rate': 0.0018897737294131286, 'epoch': 2.87}         \n",
      "{'loss': 0.4412, 'learning_rate': 0.001883512044446023, 'epoch': 2.93}          \n",
      "{'loss': 0.3219, 'learning_rate': 0.001877088354033077, 'epoch': 3.0}           \n",
      "{'loss': 0.256, 'learning_rate': 0.0018705038360561721, 'epoch': 3.07}          \n",
      "{'loss': 0.2348, 'learning_rate': 0.0018637596978873835, 'epoch': 3.13}         \n",
      "{'loss': 0.2618, 'learning_rate': 0.0018568571761675891, 'epoch': 3.2}          \n",
      "{'loss': 0.2212, 'learning_rate': 0.0018497975365797152, 'epoch': 3.27}         \n",
      "{'loss': 0.2406, 'learning_rate': 0.001842582073616649, 'epoch': 3.33}          \n",
      "{'loss': 0.2459, 'learning_rate': 0.0018352121103438802, 'epoch': 3.4}          \n",
      "{'loss': 0.297, 'learning_rate': 0.0018276889981568907, 'epoch': 3.47}          \n",
      "{'loss': 0.274, 'learning_rate': 0.001820014116533359, 'epoch': 3.53}           \n",
      "{'loss': 0.2339, 'learning_rate': 0.0018121888727802111, 'epoch': 3.6}          \n",
      "{'loss': 0.2848, 'learning_rate': 0.001804214701775569, 'epoch': 3.67}          \n",
      "{'loss': 0.2823, 'learning_rate': 0.0017960930657056437, 'epoch': 3.73}         \n",
      "{'loss': 0.212, 'learning_rate': 0.0017878254537966216, 'epoch': 3.8}           \n",
      "{'loss': 0.1903, 'learning_rate': 0.0017794133820415916, 'epoch': 3.87}         \n",
      "{'loss': 0.1928, 'learning_rate': 0.0017708583929225649, 'epoch': 3.93}         \n",
      "{'loss': 0.2735, 'learning_rate': 0.0017621620551276365, 'epoch': 4.0}          \n",
      "{'loss': 0.1648, 'learning_rate': 0.0017533259632633441, 'epoch': 4.07}         \n",
      "{'loss': 0.1233, 'learning_rate': 0.0017443517375622705, 'epoch': 4.13}         \n",
      "{'loss': 0.1811, 'learning_rate': 0.0017352410235859502, 'epoch': 4.2}          \n",
      "{'loss': 0.113, 'learning_rate': 0.0017259954919231308, 'epoch': 4.27}          \n",
      "{'loss': 0.1884, 'learning_rate': 0.0017166168378834447, 'epoch': 4.33}         \n",
      "{'loss': 0.1771, 'learning_rate': 0.0017071067811865474, 'epoch': 4.4}          \n",
      "{'loss': 0.1492, 'learning_rate': 0.0016974670656467823, 'epoch': 4.47}         \n",
      "{'loss': 0.1526, 'learning_rate': 0.0016876994588534233, 'epoch': 4.53}         \n",
      "{'loss': 0.1654, 'learning_rate': 0.001677805751846563, 'epoch': 4.6}           \n",
      "{'loss': 0.152, 'learning_rate': 0.0016677877587886955, 'epoch': 4.67}          \n",
      "{'loss': 0.1592, 'learning_rate': 0.0016576473166320645, 'epoch': 4.73}         \n",
      "{'loss': 0.1911, 'learning_rate': 0.0016473862847818277, 'epoch': 4.8}          \n",
      "{'loss': 0.1399, 'learning_rate': 0.0016370065447551077, 'epoch': 4.87}         \n",
      "{'loss': 0.2018, 'learning_rate': 0.0016265099998359867, 'epoch': 4.93}         \n",
      "{'loss': 0.1138, 'learning_rate': 0.0016158985747265107, 'epoch': 5.0}          \n",
      "{'loss': 0.0613, 'learning_rate': 0.0016051742151937654, 'epoch': 5.07}         \n",
      "{'loss': 0.0676, 'learning_rate': 0.0015943388877130897, 'epoch': 5.13}         \n",
      "{'loss': 0.1301, 'learning_rate': 0.0015833945791074943, 'epoch': 5.2}          \n",
      "{'loss': 0.1008, 'learning_rate': 0.0015723432961833438, 'epoch': 5.27}         \n",
      "{'loss': 0.135, 'learning_rate': 0.0015611870653623825, 'epoch': 5.33}          \n",
      "{'loss': 0.0917, 'learning_rate': 0.0015499279323101548, 'epoch': 5.4}          \n",
      "{'loss': 0.0972, 'learning_rate': 0.0015385679615609043, 'epoch': 5.47}         \n",
      "{'loss': 0.1012, 'learning_rate': 0.0015271092361390077, 'epoch': 5.53}         \n",
      "{'loss': 0.0749, 'learning_rate': 0.0015155538571770218, 'epoch': 5.6}          \n",
      "{'loss': 0.114, 'learning_rate': 0.001503903943530408, 'epoch': 5.67}           \n",
      "{'loss': 0.0978, 'learning_rate': 0.0014921616313890071, 'epoch': 5.73}         \n",
      "{'loss': 0.1166, 'learning_rate': 0.0014803290738853395, 'epoch': 5.8}          \n",
      "{'loss': 0.109, 'learning_rate': 0.0014684084406997903, 'epoch': 5.87}          \n",
      "{'loss': 0.1201, 'learning_rate': 0.0014564019176627689, 'epoch': 5.93}         \n",
      "{'loss': 0.118, 'learning_rate': 0.0014443117063539037, 'epoch': 6.0}           \n",
      "{'loss': 0.0665, 'learning_rate': 0.0014321400236983457, 'epoch': 6.07}         \n",
      "{'loss': 0.0725, 'learning_rate': 0.0014198891015602647, 'epoch': 6.13}         \n",
      "{'loss': 0.0476, 'learning_rate': 0.001407561186333601, 'epoch': 6.2}           \n",
      "{'loss': 0.0394, 'learning_rate': 0.0013951585385301554, 'epoch': 6.27}         \n",
      "{'loss': 0.0839, 'learning_rate': 0.00138268343236509, 'epoch': 6.33}           \n",
      "{'loss': 0.0486, 'learning_rate': 0.0013701381553399147, 'epoch': 6.4}          \n",
      "{'loss': 0.0704, 'learning_rate': 0.0013575250078230398, 'epoch': 6.47}         \n",
      "{'loss': 0.0644, 'learning_rate': 0.0013448463026279704, 'epoch': 6.53}         \n",
      "{'loss': 0.0893, 'learning_rate': 0.0013321043645892119, 'epoch': 6.6}          \n",
      "{'loss': 0.0604, 'learning_rate': 0.00131930153013598, 'epoch': 6.67}           \n",
      "{'loss': 0.0623, 'learning_rate': 0.0013064401468637792, 'epoch': 6.73}         \n",
      "{'loss': 0.0563, 'learning_rate': 0.0012935225731039348, 'epoch': 6.8}          \n",
      "{'loss': 0.0536, 'learning_rate': 0.0012805511774911585, 'epoch': 6.87}         \n",
      "{'loss': 0.0178, 'learning_rate': 0.0012675283385292211, 'epoch': 6.93}         \n",
      "{'loss': 0.0735, 'learning_rate': 0.001254456444154818, 'epoch': 7.0}           \n",
      "{'loss': 0.0182, 'learning_rate': 0.0012413378912997058, 'epoch': 7.07}         \n",
      "{'loss': 0.0261, 'learning_rate': 0.001228175085451186, 'epoch': 7.13}          \n",
      "{'loss': 0.0271, 'learning_rate': 0.0012149704402110242, 'epoch': 7.2}          \n",
      "{'loss': 0.0322, 'learning_rate': 0.0012017263768528774, 'epoch': 7.27}         \n",
      "{'loss': 0.0374, 'learning_rate': 0.0011884453238783185, 'epoch': 7.33}         \n",
      "{'loss': 0.0424, 'learning_rate': 0.0011751297165715309, 'epoch': 7.4}          \n",
      "{'loss': 0.0625, 'learning_rate': 0.001161781996552765, 'epoch': 7.47}          \n",
      "{'loss': 0.0253, 'learning_rate': 0.001148404611330626, 'epoch': 7.53}          \n",
      "{'loss': 0.0222, 'learning_rate': 0.0011350000138532902, 'epoch': 7.6}          \n",
      "{'loss': 0.0479, 'learning_rate': 0.001121570662058715, 'epoch': 7.67}          \n",
      "{'loss': 0.0278, 'learning_rate': 0.0011081190184239417, 'epoch': 7.73}         \n",
      "{'loss': 0.0202, 'learning_rate': 0.001094647549513561, 'epoch': 7.8}           \n",
      "{'loss': 0.0263, 'learning_rate': 0.0010811587255274314, 'epoch': 7.87}         \n",
      "{'loss': 0.0541, 'learning_rate': 0.0010676550198477292, 'epoch': 7.93}         \n",
      "{'loss': 0.0547, 'learning_rate': 0.0010541389085854177, 'epoch': 8.0}          \n",
      "{'loss': 0.0115, 'learning_rate': 0.0010406128701262128, 'epoch': 8.07}         \n",
      "{'loss': 0.0115, 'learning_rate': 0.0010270793846761347, 'epoch': 8.13}         \n",
      "{'loss': 0.0158, 'learning_rate': 0.001013540933806722, 'epoch': 8.2}           \n",
      "{'loss': 0.016, 'learning_rate': 0.001, 'epoch': 8.27}                          \n",
      "{'loss': 0.0138, 'learning_rate': 0.0009864590661932784, 'epoch': 8.33}         \n",
      "{'loss': 0.0215, 'learning_rate': 0.0009729206153238657, 'epoch': 8.4}          \n",
      "{'loss': 0.0262, 'learning_rate': 0.0009593871298737871, 'epoch': 8.47}         \n",
      "{'loss': 0.0293, 'learning_rate': 0.0009458610914145825, 'epoch': 8.53}         \n",
      "{'loss': 0.0196, 'learning_rate': 0.0009323449801522709, 'epoch': 8.6}          \n",
      "{'loss': 0.0175, 'learning_rate': 0.0009188412744725689, 'epoch': 8.67}         \n",
      "{'loss': 0.024, 'learning_rate': 0.000905352450486439, 'epoch': 8.73}           \n",
      "{'loss': 0.0097, 'learning_rate': 0.0008918809815760584, 'epoch': 8.8}          \n",
      "{'loss': 0.0256, 'learning_rate': 0.000878429337941285, 'epoch': 8.87}          \n",
      "{'loss': 0.0286, 'learning_rate': 0.0008649999861467098, 'epoch': 8.93}         \n",
      "{'loss': 0.0335, 'learning_rate': 0.0008515953886693739, 'epoch': 9.0}          \n",
      "{'loss': 0.0146, 'learning_rate': 0.0008382180034472353, 'epoch': 9.07}         \n",
      "{'loss': 0.0063, 'learning_rate': 0.0008248702834284693, 'epoch': 9.13}         \n",
      "{'loss': 0.0055, 'learning_rate': 0.0008115546761216821, 'epoch': 9.2}          \n",
      "{'loss': 0.0079, 'learning_rate': 0.0007982736231471224, 'epoch': 9.27}         \n",
      "{'loss': 0.0105, 'learning_rate': 0.0007850295597889759, 'epoch': 9.33}         \n",
      "{'loss': 0.0084, 'learning_rate': 0.0007718249145488142, 'epoch': 9.4}          \n",
      "{'loss': 0.0136, 'learning_rate': 0.0007586621087002945, 'epoch': 9.47}         \n",
      "{'loss': 0.0109, 'learning_rate': 0.0007455435558451823, 'epoch': 9.53}         \n",
      "{'loss': 0.0057, 'learning_rate': 0.0007324716614707794, 'epoch': 9.6}          \n",
      "{'loss': 0.0077, 'learning_rate': 0.0007194488225088416, 'epoch': 9.67}         \n",
      "{'loss': 0.0151, 'learning_rate': 0.0007064774268960653, 'epoch': 9.73}         \n",
      "{'loss': 0.0875, 'learning_rate': 0.000693559853136221, 'epoch': 9.8}           \n",
      "{'loss': 0.0148, 'learning_rate': 0.0006806984698640202, 'epoch': 9.87}         \n",
      "{'loss': 0.0097, 'learning_rate': 0.0006678956354107882, 'epoch': 9.93}         \n",
      "{'loss': 0.0106, 'learning_rate': 0.0006551536973720298, 'epoch': 10.0}         \n",
      "{'loss': 0.0127, 'learning_rate': 0.0006424749921769599, 'epoch': 10.07}        \n",
      "{'loss': 0.0083, 'learning_rate': 0.0006298618446600856, 'epoch': 10.13}        \n",
      "{'loss': 0.0049, 'learning_rate': 0.0006173165676349102, 'epoch': 10.2}         \n",
      "{'loss': 0.0063, 'learning_rate': 0.0006048414614698447, 'epoch': 10.27}        \n",
      "{'loss': 0.0046, 'learning_rate': 0.0005924388136663992, 'epoch': 10.33}        \n",
      "{'loss': 0.0128, 'learning_rate': 0.0005801108984397354, 'epoch': 10.4}         \n",
      "{'loss': 0.0092, 'learning_rate': 0.0005678599763016543, 'epoch': 10.47}        \n",
      "{'loss': 0.0065, 'learning_rate': 0.0005556882936460966, 'epoch': 10.53}        \n",
      "{'loss': 0.0041, 'learning_rate': 0.0005435980823372311, 'epoch': 10.6}         \n",
      "{'loss': 0.0086, 'learning_rate': 0.00053159155930021, 'epoch': 10.67}          \n",
      "{'loss': 0.0128, 'learning_rate': 0.0005196709261146606, 'epoch': 10.73}        \n",
      "{'loss': 0.0087, 'learning_rate': 0.0005078383686109927, 'epoch': 10.8}         \n",
      "{'loss': 0.0065, 'learning_rate': 0.0004960960564695923, 'epoch': 10.87}        \n",
      "{'loss': 0.0087, 'learning_rate': 0.00048444614282297814, 'epoch': 10.93}       \n",
      "{'loss': 0.0079, 'learning_rate': 0.0004728907638609925, 'epoch': 11.0}         \n",
      "{'loss': 0.0066, 'learning_rate': 0.0004614320384390959, 'epoch': 11.07}        \n",
      "{'loss': 0.0063, 'learning_rate': 0.0004500720676898452, 'epoch': 11.13}        \n",
      "{'loss': 0.0076, 'learning_rate': 0.00043881293463761775, 'epoch': 11.2}        \n",
      "{'loss': 0.0036, 'learning_rate': 0.0004276567038166562, 'epoch': 11.27}        \n",
      "{'loss': 0.0058, 'learning_rate': 0.000416605420892506, 'epoch': 11.33}         \n",
      "{'loss': 0.0035, 'learning_rate': 0.0004056611122869106, 'epoch': 11.4}         \n",
      "{'loss': 0.0063, 'learning_rate': 0.0003948257848062351, 'epoch': 11.47}        \n",
      "{'loss': 0.005, 'learning_rate': 0.0003841014252734896, 'epoch': 11.53}         \n",
      "{'loss': 0.0044, 'learning_rate': 0.0003734900001640135, 'epoch': 11.6}         \n",
      "{'loss': 0.0085, 'learning_rate': 0.00036299345524489244, 'epoch': 11.67}       \n",
      "{'loss': 0.0105, 'learning_rate': 0.00035261371521817244, 'epoch': 11.73}       \n",
      "{'loss': 0.0054, 'learning_rate': 0.00034235268336793546, 'epoch': 11.8}        \n",
      "{'loss': 0.0048, 'learning_rate': 0.00033221224121130464, 'epoch': 11.87}       \n",
      "{'loss': 0.0033, 'learning_rate': 0.00032219424815343735, 'epoch': 11.93}       \n",
      "{'loss': 0.0034, 'learning_rate': 0.00031230054114657655, 'epoch': 12.0}        \n",
      "{'loss': 0.0123, 'learning_rate': 0.00030253293435321795, 'epoch': 12.07}       \n",
      "{'loss': 0.0046, 'learning_rate': 0.00029289321881345256, 'epoch': 12.13}       \n",
      "{'loss': 0.0035, 'learning_rate': 0.0002833831621165553, 'epoch': 12.2}         \n",
      "{'loss': 0.0057, 'learning_rate': 0.00027400450807686937, 'epoch': 12.27}       \n",
      "{'loss': 0.0032, 'learning_rate': 0.0002647589764140499, 'epoch': 12.33}        \n",
      "{'loss': 0.0048, 'learning_rate': 0.00025564826243772967, 'epoch': 12.4}        \n",
      "{'loss': 0.0037, 'learning_rate': 0.0002466740367366562, 'epoch': 12.47}        \n",
      "{'loss': 0.0037, 'learning_rate': 0.00023783794487236367, 'epoch': 12.53}       \n",
      "{'loss': 0.0039, 'learning_rate': 0.00022914160707743537, 'epoch': 12.6}        \n",
      "{'loss': 0.0043, 'learning_rate': 0.0002205866179584084, 'epoch': 12.67}        \n",
      "{'loss': 0.0035, 'learning_rate': 0.0002121745462033784, 'epoch': 12.73}        \n",
      "{'loss': 0.0041, 'learning_rate': 0.00020390693429435625, 'epoch': 12.8}        \n",
      "{'loss': 0.0025, 'learning_rate': 0.00019578529822443093, 'epoch': 12.87}       \n",
      "{'loss': 0.0053, 'learning_rate': 0.00018781112721978898, 'epoch': 12.93}       \n",
      "{'loss': 0.0054, 'learning_rate': 0.00017998588346664114, 'epoch': 13.0}        \n",
      "{'loss': 0.0036, 'learning_rate': 0.00017231100184310954, 'epoch': 13.07}       \n",
      "{'loss': 0.0027, 'learning_rate': 0.0001647878896561199, 'epoch': 13.13}        \n",
      "{'loss': 0.0026, 'learning_rate': 0.00015741792638335094, 'epoch': 13.2}        \n",
      "{'loss': 0.0033, 'learning_rate': 0.0001502024634202851, 'epoch': 13.27}        \n",
      "{'loss': 0.0033, 'learning_rate': 0.00014314282383241095, 'epoch': 13.33}       \n",
      "{'loss': 0.0049, 'learning_rate': 0.00013624030211261683, 'epoch': 13.4}        \n",
      "{'loss': 0.0047, 'learning_rate': 0.00012949616394382802, 'epoch': 13.47}       \n",
      "{'loss': 0.0029, 'learning_rate': 0.00012291164596692306, 'epoch': 13.53}       \n",
      "{'loss': 0.0032, 'learning_rate': 0.00011648795555397717, 'epoch': 13.6}        \n",
      "{'loss': 0.0037, 'learning_rate': 0.00011022627058687162, 'epoch': 13.67}       \n",
      "{'loss': 0.0039, 'learning_rate': 0.00010412773924131202, 'epoch': 13.73}       \n",
      "{'loss': 0.0024, 'learning_rate': 9.8193479776292e-05, 'epoch': 13.8}           \n",
      "{'loss': 0.0039, 'learning_rate': 9.24245803290431e-05, 'epoch': 13.87}         \n",
      "{'loss': 0.0064, 'learning_rate': 8.682209871550883e-05, 'epoch': 13.93}        \n",
      "{'loss': 0.0053, 'learning_rate': 8.138706223637827e-05, 'epoch': 14.0}         \n",
      "{'loss': 0.0026, 'learning_rate': 7.612046748871326e-05, 'epoch': 14.07}        \n",
      "{'loss': 0.0032, 'learning_rate': 7.102328018320858e-05, 'epoch': 14.13}        \n",
      "{'loss': 0.0027, 'learning_rate': 6.609643496711349e-05, 'epoch': 14.2}         \n",
      "{'loss': 0.0059, 'learning_rate': 6.13408352528495e-05, 'epoch': 14.27}         \n",
      "{'loss': 0.0047, 'learning_rate': 5.675735305235696e-05, 'epoch': 14.33}        \n",
      "{'loss': 0.0022, 'learning_rate': 5.234682881719766e-05, 'epoch': 14.4}         \n",
      "{'loss': 0.0041, 'learning_rate': 4.8110071284444444e-05, 'epoch': 14.47}       \n",
      "{'loss': 0.0044, 'learning_rate': 4.404785732838845e-05, 'epoch': 14.53}        \n",
      "{'loss': 0.0018, 'learning_rate': 4.016093181808622e-05, 'epoch': 14.6}         \n",
      "{'loss': 0.0036, 'learning_rate': 3.645000748077709e-05, 'epoch': 14.67}        \n",
      "{'loss': 0.0032, 'learning_rate': 3.291576477119329e-05, 'epoch': 14.73}        \n",
      "{'loss': 0.0033, 'learning_rate': 2.9558851746788517e-05, 'epoch': 14.8}        \n",
      "{'loss': 0.0037, 'learning_rate': 2.6379883948907e-05, 'epoch': 14.87}          \n",
      "{'loss': 0.0033, 'learning_rate': 2.3379444289913342e-05, 'epoch': 14.93}       \n",
      "{'loss': 0.0045, 'learning_rate': 2.055808294630823e-05, 'epoch': 15.0}         \n",
      "{'loss': 0.0046, 'learning_rate': 1.791631725784404e-05, 'epoch': 15.07}        \n",
      "{'loss': 0.0029, 'learning_rate': 1.545463163266303e-05, 'epoch': 15.13}        \n",
      "{'loss': 0.0026, 'learning_rate': 1.317347745847386e-05, 'epoch': 15.2}         \n",
      "{'loss': 0.0035, 'learning_rate': 1.1073273019782448e-05, 'epoch': 15.27}       \n",
      "{'loss': 0.0043, 'learning_rate': 9.154403421193225e-06, 'epoch': 15.33}        \n",
      "{'loss': 0.0033, 'learning_rate': 7.4172205167944985e-06, 'epoch': 15.4}        \n",
      "{'loss': 0.0053, 'learning_rate': 5.862042845640403e-06, 'epoch': 15.47}        \n",
      "{'loss': 0.0037, 'learning_rate': 4.489155573341841e-06, 'epoch': 15.53}        \n",
      "{'loss': 0.0026, 'learning_rate': 3.298810439777311e-06, 'epoch': 15.6}         \n",
      "{'loss': 0.0024, 'learning_rate': 2.2912257129320546e-06, 'epoch': 15.67}       \n",
      "{'loss': 0.0027, 'learning_rate': 1.466586148876181e-06, 'epoch': 15.73}        \n",
      "{'loss': 0.0037, 'learning_rate': 8.250429578855467e-07, 'epoch': 15.8}         \n",
      "{'loss': 0.003, 'learning_rate': 3.6671377671604334e-07, 'epoch': 15.87}        \n",
      "{'loss': 0.0032, 'learning_rate': 9.168264703285357e-08, 'epoch': 15.93}        \n",
      "{'loss': 0.0034, 'learning_rate': 0.0, 'epoch': 16.0}                           \n",
      "{'train_runtime': 348.5934, 'train_samples_per_second': 2.708, 'train_steps_per_second': 0.688, 'train_loss': 0.17155027196956021, 'epoch': 16.0}\n",
      "100%|█████████████████████████████████████████| 240/240 [05:48<00:00,  1.45s/it]\n"
     ]
    }
   ],
   "source": [
    "!python llava/train/train.py \\\n",
    "  --model_name_or_path '/workspace/LLaVA-Med/Model/LLaVA-7b-v0' \\\n",
    "  --data_path '/workspace/LLaVA-Med/converted_data-3.json' \\\n",
    "  --image_folder '/workspace/FINAL_DATA-2/Images' \\\n",
    "  --tune_mm_mlp_adapter True \\\n",
    "  --output_dir '/workspace/LLaVA-Med/Model/fine_tuned-med-llava' \\\n",
    "  --vision_tower 'openai/clip-vit-large-patch14' \\\n",
    "  --mm_vision_select_layer -2 \\\n",
    "  --mm_use_im_start_end True \\\n",
    "  --bf16 True \\\n",
    "  --num_train_epochs 16 \\\n",
    "  --per_device_train_batch_size 4 \\\n",
    "  --per_device_eval_batch_size 1 \\\n",
    "  --gradient_accumulation_steps 1 \\\n",
    "  --evaluation_strategy \"no\" \\\n",
    "  --save_strategy \"steps\" \\\n",
    "  --save_steps 1000 \\\n",
    "  --save_total_limit 3 \\\n",
    "  --learning_rate 2e-3 \\\n",
    "  --weight_decay 0. \\\n",
    "  --warmup_ratio 0.03 \\\n",
    "  --lr_scheduler_type \"cosine\" \\\n",
    "  --logging_steps 1 \\\n",
    "  --tf32 True \\\n",
    "  --model_max_length 1024 \\\n",
    "  --lazy_preprocess True \\\n",
    "  --gradient_checkpointing True \\\n",
    "  --dataloader_num_workers 8 \\\n",
    "  --report_to none\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c46153c-f9bb-49bd-9ef9-481b98ec8ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/LLaVA-Med/Model/LLaVA-Med-Retina\n"
     ]
    }
   ],
   "source": [
    "%cd /workspace/LLaVA-Med/Model/LLaVA-Med-Retina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "859b970b-a5f6-4e97-9655-1e192d30674f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (5.27.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece\n",
    "!pip install protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463b984e-776c-4e05-b2fd-178f1b335d72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33498273-e92d-485a-b505-cd805c187765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (3.23.0)\n",
      "Requirement already satisfied: aiofiles in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.4)\n",
      "Requirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (5.4.0)\n",
      "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.112.1)\n",
      "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio) (2024.6.1)\n",
      "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.24.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (2.2.0)\n",
      "Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gradio) (3.9.2)\n",
      "Requirement already satisfied: mdit-py-plugins<=0.3.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gradio) (1.24.1)\n",
      "Requirement already satisfied: orjson in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from gradio) (9.3.0)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from gradio) (2.8.2)\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.9)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gradio) (2.31.0)\n",
      "Requirement already satisfied: semantic-version in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
      "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (from gradio) (0.30.6)\n",
      "Requirement already satisfied: websockets>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (12.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (4.19.2)\n",
      "Requirement already satisfied: narwhals>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (1.4.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (23.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->gradio) (3.9.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->gradio) (4.66.5)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.0.0->markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
      "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (2.0.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (2.3.7)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (4.0.3)\n",
      "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.38.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->gradio) (2.20.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (4.0.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (2022.12.7)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.0.5)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.4)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->gradio) (0.14.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib->gradio) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->gradio) (2.1.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gradio) (2.2.2)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->gradio) (8.1.7)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio) (1.0.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib->gradio) (1.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio) (1.1.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ade4671c-7cb8-4369-b5af-3ca877b1d7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output: Yes, the axial T1-weighted MRI image shows evidence of loss of gray-white matter differentiation in the ischemic area. This is marked by the arrow in the image.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Define the model name (update this to your actual model path)\n",
    "model_name = \"/workspace/LLaVA-Med/Model/fine_tuned-med-llava\"\n",
    "\n",
    "def infer_llava_med(image_path, question):\n",
    "    # Command to run the LLaVA-Med model using the provided image and question\n",
    "    command = [\n",
    "        \"python\", \"-m\", \"llava.eval.run_llava\",\n",
    "        \"--model-name\", model_name,\n",
    "        \"--image-file\", image_path,\n",
    "        \"--query\", question\n",
    "    ]\n",
    "\n",
    "    # Run the command and capture the output\n",
    "    result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "    # Return the standard output (predictions)\n",
    "    return result.stdout.strip()\n",
    "    \n",
    "\n",
    "# Example usage\n",
    "image_path = \"/workspace/FINAL_DATA-2/Eval/Ischemia.jpeg\"\n",
    "question = \"Does the image show any evidence of loss of gray-white matter differentiation in the ischemic area?\"\n",
    "\n",
    "# Perform inference and print the output\n",
    "output = infer_llava_med(image_path, question)\n",
    "print(f\"Model Output: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da1eb5e-a823-4c6a-a10e-5c16743dcb7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7173b2d1-66bc-4d36-acbd-7e0cc6476bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d470924d-6699-42f6-a40c-bafed44fc2ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fb85ce-0b78-455c-a26a-795eb623b4c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91f793b-2f55-40c8-89ce-ec209751c48a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd249ae8-df33-438e-84af-f1b8a322a722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/LLaVA-Med/Model/LLaVA-Med-Retina\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd \"/workspace/LLaVA-Med/Model/LLaVA-Med-Retina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319ce57b-9298-45f4-85e6-894fd2f5448c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "vibhor.sehgal (Jul 21, 2024, 5:36:11 PM)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
